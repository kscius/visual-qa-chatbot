# ğŸ–¼ï¸ Visual Q&A Chatbot

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js Version](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen)](https://nodejs.org/)
[![React](https://img.shields.io/badge/react-18.3.1-blue)](https://reactjs.org/)

> A full-stack AI-powered application that allows users to upload images and ask questions about them using computer vision and natural language processing.

[English](#english) | [EspaÃ±ol](#espaÃ±ol)

---

## English

### ğŸ“‹ Table of Contents

- [Features](#features)
- [Demo](#demo)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Getting Started](#getting-started)
- [Configuration](#configuration)
- [API Documentation](#api-documentation)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)

### âœ¨ Features

- ğŸ¨ **Image Upload**: Support for JPEG, PNG, GIF, and WEBP formats (max 10MB)
- ğŸ” **Advanced Vision AI**: Detailed image analysis including:
  - Visual description (objects, colors, composition)
  - OCR (text extraction)
  - Event information extraction (for posters/flyers)
  - Character and brand recognition
- ğŸ’¬ **Interactive Chat**: Natural language Q&A about uploaded images
- ğŸ”’ **Session Management**: 5-question limit per image with automatic cleanup
- ğŸ¯ **Smart Context**: AI answers based solely on image description
- ğŸ“± **Responsive Design**: Works on desktop and mobile devices
- âš¡ **Real-time Feedback**: Loading states and error handling

### ğŸ¬ Demo

1. Upload an image (event poster, product photo, chart, etc.)
2. AI analyzes and generates a detailed description
3. Ask up to 5 questions about the image
4. Get AI-powered answers based on the image content
5. Upload a new image to continue

### ğŸ› ï¸ Tech Stack

**Frontend:**
- React 18 with Hooks
- Vite (build tool)
- CSS Modules
- Fetch API

**Backend:**
- Node.js + Express
- OpenAI API (GPT-4o for vision, GPT-4o-mini for chat)
- Multer (file uploads)
- In-memory session storage (Map)

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend     â”‚
â”‚  (Vite)             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP API
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express Backend    â”‚
â”‚  - Routes           â”‚
â”‚  - Services         â”‚
â”‚  - Session Store    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI APIs        â”‚
â”‚  - Vision (GPT-4o)  â”‚
â”‚  - Chat (GPT-4o-mini)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flow:**
1. User uploads image â†’ Vision API generates detailed description
2. Description stored in session (with unique session ID)
3. User asks questions â†’ NLP API answers based on description
4. After 5 questions â†’ session expires, new image required

### ğŸš€ Getting Started

#### Prerequisites

- Node.js 18+ and npm/pnpm/yarn
- OpenAI API key ([get one here](https://platform.openai.com/api-keys))

#### Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/visual-qa-chatbot.git
cd visual-qa-chatbot
```

2. **Install backend dependencies**

```bash
cd backend
npm install
```

3. **Install frontend dependencies**

```bash
cd ../frontend
npm install
```

4. **Configure environment variables**

Create a `.env` file in the `backend/` directory:

```env
OPENAI_API_KEY=sk-your-actual-api-key-here
VISION_MODEL=gpt-4o
NLP_MODEL=gpt-4o-mini
PORT=3000
```

See [Configuration](#configuration) for all available options.

#### Running the Application

**Development Mode:**

1. **Start the backend** (from `backend/` directory):

```bash
npm run dev
```

Backend will run on `http://localhost:3000`

2. **Start the frontend** (from `frontend/` directory, new terminal):

```bash
npm run dev
```

Frontend will run on `http://localhost:5173`

3. **Open your browser** and navigate to `http://localhost:5173`

**Production Mode:**

```bash
# Backend
cd backend
npm start

# Frontend (build first)
cd frontend
npm run build
npm run preview
```

### âš™ï¸ Configuration

#### Environment Variables

Create a `.env` file in `backend/` directory with the following variables:

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `OPENAI_API_KEY` | Your OpenAI API key | - | âœ… Yes |
| `VISION_MODEL` | Model for image analysis | `gpt-4o` | No |
| `NLP_MODEL` | Model for chat responses | `gpt-4o-mini` | No |
| `PORT` | Backend server port | `3000` | No |

#### Model Selection

**Vision Models** (for image analysis):
- `gpt-4o` - Best quality, higher cost
- `gpt-4o-mini` - Basic vision, lower cost

**NLP Models** (for Q&A):
- `gpt-4o-mini` - Recommended, good balance
- `gpt-4o` - Higher quality, higher cost
- `gpt-3.5-turbo` - Faster, lower cost

### ğŸ“š API Documentation

#### `POST /api/upload-image`

Upload an image and create a new session.

**Request:**
- `Content-Type`: `multipart/form-data`
- Body: `image` (file field)

**Response:**
```json
{
  "sessionId": "uuid-v4",
  "descriptionPreview": "First 200 chars...",
  "remainingQuestions": 5,
  "message": "Image processed successfully..."
}
```

#### `POST /api/chat`

Ask a question about the uploaded image.

**Request:**
```json
{
  "sessionId": "uuid-v4",
  "question": "What color is the main object?"
}
```

**Response:**
```json
{
  "answer": "The main object is red...",
  "remainingQuestions": 4,
  "questionsUsed": 1,
  "sessionActive": true
}
```

**Error Response (Session Expired):**
```json
{
  "error": "SESSION_EXPIRED",
  "message": "You have reached the 5-question limit...",
  "questionsUsed": 5
}
```

#### `GET /api/health`

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T00:00:00.000Z"
}
```

### ğŸš¢ Deployment

#### Deploying to Production

**Backend (Node.js):**
- Deploy to: Heroku, Railway, Render, AWS, DigitalOcean
- Set environment variables in platform dashboard
- Ensure `uploads/` directory is writable

**Frontend (React):**
- Build: `npm run build`
- Deploy to: Vercel, Netlify, AWS S3 + CloudFront
- Update API base URL if backend is on different domain

**Recommended Improvements for Production:**
- Use Redis for session storage (multi-instance support)
- Store images in S3/Cloudinary instead of local disk
- Add authentication (JWT, OAuth)
- Implement rate limiting
- Add monitoring (Sentry, Datadog)
- Use HTTPS

### ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ™ Acknowledgments

- OpenAI for GPT-4o and GPT-4o-mini APIs
- React and Vite communities
- All contributors

---

## EspaÃ±ol

### ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [DemostraciÃ³n](#demostraciÃ³n)
- [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
- [Arquitectura](#arquitectura-1)
- [Comenzando](#comenzando)
- [ConfiguraciÃ³n](#configuraciÃ³n-1)
- [DocumentaciÃ³n de API](#documentaciÃ³n-de-api)
- [Despliegue](#despliegue)
- [Contribuir](#contribuir)
- [Licencia](#licencia-1)

### âœ¨ CaracterÃ­sticas

- ğŸ¨ **Carga de ImÃ¡genes**: Soporte para formatos JPEG, PNG, GIF y WEBP (mÃ¡x 10MB)
- ğŸ” **IA de VisiÃ³n Avanzada**: AnÃ¡lisis detallado de imÃ¡genes incluyendo:
  - DescripciÃ³n visual (objetos, colores, composiciÃ³n)
  - OCR (extracciÃ³n de texto)
  - ExtracciÃ³n de informaciÃ³n de eventos (para posters/flyers)
  - Reconocimiento de personajes y marcas
- ğŸ’¬ **Chat Interactivo**: Preguntas y respuestas en lenguaje natural sobre imÃ¡genes
- ğŸ”’ **GestiÃ³n de Sesiones**: LÃ­mite de 5 preguntas por imagen con limpieza automÃ¡tica
- ğŸ¯ **Contexto Inteligente**: IA responde basÃ¡ndose Ãºnicamente en la descripciÃ³n de la imagen
- ğŸ“± **DiseÃ±o Responsivo**: Funciona en dispositivos de escritorio y mÃ³viles
- âš¡ **RetroalimentaciÃ³n en Tiempo Real**: Estados de carga y manejo de errores

### ğŸ¬ DemostraciÃ³n

1. Sube una imagen (poster de evento, foto de producto, grÃ¡fico, etc.)
2. La IA analiza y genera una descripciÃ³n detallada
3. Haz hasta 5 preguntas sobre la imagen
4. ObtÃ©n respuestas generadas por IA basadas en el contenido de la imagen
5. Sube una nueva imagen para continuar

### ğŸ› ï¸ Stack TecnolÃ³gico

**Frontend:**
- React 18 con Hooks
- Vite (herramienta de build)
- CSS Modules
- Fetch API

**Backend:**
- Node.js + Express
- API de OpenAI (GPT-4o para visiÃ³n, GPT-4o-mini para chat)
- Multer (carga de archivos)
- Almacenamiento de sesiones en memoria (Map)

### ğŸ—ï¸ Arquitectura

El sistema sigue una arquitectura cliente-servidor con integraciÃ³n de APIs de IA:

**Flujo:**
1. Usuario sube imagen â†’ API de VisiÃ³n genera descripciÃ³n detallada
2. DescripciÃ³n almacenada en sesiÃ³n (con ID de sesiÃ³n Ãºnico)
3. Usuario hace preguntas â†’ API de NLP responde basÃ¡ndose en descripciÃ³n
4. DespuÃ©s de 5 preguntas â†’ sesiÃ³n expira, se requiere nueva imagen

### ğŸš€ Comenzando

#### Prerrequisitos

- Node.js 18+ y npm/pnpm/yarn
- Clave API de OpenAI ([obtÃ©nla aquÃ­](https://platform.openai.com/api-keys))

#### InstalaciÃ³n

1. **Clonar el repositorio**

```bash
git clone https://github.com/tuusuario/visual-qa-chatbot.git
cd visual-qa-chatbot
```

2. **Instalar dependencias del backend**

```bash
cd backend
npm install
```

3. **Instalar dependencias del frontend**

```bash
cd ../frontend
npm install
```

4. **Configurar variables de entorno**

Crea un archivo `.env` en el directorio `backend/`:

```env
OPENAI_API_KEY=sk-tu-clave-api-real-aqui
VISION_MODEL=gpt-4o
NLP_MODEL=gpt-4o-mini
PORT=3000
```

Ver [ConfiguraciÃ³n](#configuraciÃ³n-1) para todas las opciones disponibles.

#### Ejecutar la AplicaciÃ³n

**Modo Desarrollo:**

1. **Iniciar el backend** (desde directorio `backend/`):

```bash
npm run dev
```

El backend correrÃ¡ en `http://localhost:3000`

2. **Iniciar el frontend** (desde directorio `frontend/`, nueva terminal):

```bash
npm run dev
```

El frontend correrÃ¡ en `http://localhost:5173`

3. **Abrir tu navegador** y navegar a `http://localhost:5173`

### âš™ï¸ ConfiguraciÃ³n

#### Variables de Entorno

Crea un archivo `.env` en el directorio `backend/` con las siguientes variables:

| Variable | DescripciÃ³n | Por Defecto | Requerida |
|----------|-------------|-------------|-----------|
| `OPENAI_API_KEY` | Tu clave API de OpenAI | - | âœ… SÃ­ |
| `VISION_MODEL` | Modelo para anÃ¡lisis de imÃ¡genes | `gpt-4o` | No |
| `NLP_MODEL` | Modelo para respuestas de chat | `gpt-4o-mini` | No |
| `PORT` | Puerto del servidor backend | `3000` | No |

#### SelecciÃ³n de Modelos

**Modelos de VisiÃ³n** (para anÃ¡lisis de imÃ¡genes):
- `gpt-4o` - Mejor calidad, mayor costo
- `gpt-4o-mini` - VisiÃ³n bÃ¡sica, menor costo

**Modelos NLP** (para Q&A):
- `gpt-4o-mini` - Recomendado, buen balance
- `gpt-4o` - Mayor calidad, mayor costo
- `gpt-3.5-turbo` - MÃ¡s rÃ¡pido, menor costo

### ğŸš¢ Despliegue

**Backend (Node.js):**
- Desplegar en: Heroku, Railway, Render, AWS, DigitalOcean
- Configurar variables de entorno en el dashboard de la plataforma

**Frontend (React):**
- Build: `npm run build`
- Desplegar en: Vercel, Netlify, AWS S3 + CloudFront

**Mejoras recomendadas para producciÃ³n:**
- Usar Redis para almacenamiento de sesiones
- Almacenar imÃ¡genes en S3/Cloudinary
- Agregar autenticaciÃ³n
- Implementar rate limiting
- Agregar monitoreo

### ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Por favor consulta [CONTRIBUTING.md](CONTRIBUTING.md) para mÃ¡s detalles.

### ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

**Hecho con â¤ï¸ por la comunidad Open Source**
